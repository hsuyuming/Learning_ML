{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.8.2\n",
      "TFDV version: 1.8.0\n"
     ]
    }
   ],
   "source": [
    "from ml_metadata.metadata_store import metadata_store\n",
    "from ml_metadata.proto import metadata_store_pb2\n",
    "\n",
    "import tensorflow as tf\n",
    "print('TF version: {}'.format(tf.__version__))\n",
    "\n",
    "import tensorflow_data_validation as tfdv\n",
    "print('TFDV version: {}'.format(tfdv.version.__version__))\n",
    "\n",
    "import urllib\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's what we downloaded:\n",
      "\u001b[34meval\u001b[m\u001b[m    \u001b[34mserving\u001b[m\u001b[m \u001b[34mtrain\u001b[m\u001b[m\n",
      "\n",
      "data/eval:\n",
      "data.csv\n",
      "\n",
      "data/serving:\n",
      "data.csv\n",
      "\n",
      "data/train:\n",
      "data.csv\n"
     ]
    }
   ],
   "source": [
    "# Download the zip file from GCP and unzip it\n",
    "url = 'https://storage.googleapis.com/artifacts.tfx-oss-public.appspot.com/datasets/chicago_data.zip'\n",
    "zip, headers = urllib.request.urlretrieve(url)\n",
    "zipfile.ZipFile(zip).extractall()\n",
    "zipfile.ZipFile(zip).close()\n",
    "\n",
    "print(\"Here's what we downloaded:\")\n",
    "!ls -R data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ML Metadata's Storage Backend\n",
    "connection_config = metadata_store_pb2.ConnectionConfig()\n",
    "connection_config.fake_database.SetInParent()\n",
    "store = metadata_store.MetadataStore(connection_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ml_metadata.metadata_store.metadata_store.MetadataStore at 0x1607da460>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ArtifacType for the input dataset\n",
    "data_artifact_type = metadata_store_pb2.ArtifactType()\n",
    "data_artifact_type.name = 'DataSet'\n",
    "data_artifact_type.properties['name'] = metadata_store_pb2.STRING\n",
    "data_artifact_type.properties['split'] =  metadata_store_pb2.STRING\n",
    "data_artifact_type.properties['version'] = metadata_store_pb2.INT\n",
    "\n",
    "data_artifact_type_id = store.put_artifact_type(data_artifact_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ArtifactType for Schema\n",
    "schema_artifact_type = metadata_store_pb2.ArtifactType()\n",
    "schema_artifact_type.name = 'Schema'\n",
    "schema_artifact_type.properties['name'] = metadata_store_pb2.STRING\n",
    "schema_artifact_type.properties['version'] = metadata_store_pb2.INT\n",
    "\n",
    "# Register artifact type to the Metadata Store\n",
    "schema_artifact_type_id = store.put_artifact_type(schema_artifact_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data artifact type:\n",
      " name: \"DataSet\"\n",
      "properties {\n",
      "  key: \"name\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"split\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "\n",
      "Schema artifact type:\n",
      " name: \"Schema\"\n",
      "properties {\n",
      "  key: \"name\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "\n",
      "Data artifact type ID: 10\n",
      "Schema artifact type ID: 11\n"
     ]
    }
   ],
   "source": [
    "print('Data artifact type:\\n', data_artifact_type)\n",
    "print('Schema artifact type:\\n', schema_artifact_type)\n",
    "print('Data artifact type ID:', data_artifact_type_id)\n",
    "print('Schema artifact type ID:', schema_artifact_type_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data validation execution type:\n",
      " name: \"Data Validation\"\n",
      "properties {\n",
      "  key: \"state\"\n",
      "  value: STRING\n",
      "}\n",
      "\n",
      "Data validation execution type ID: 12\n"
     ]
    }
   ],
   "source": [
    "# Create ExecutionType for Data Validation component\n",
    "dv_execution_type = metadata_store_pb2.ExecutionType()\n",
    "dv_execution_type.name = 'Data Validation'\n",
    "dv_execution_type.properties['state'] = metadata_store_pb2.STRING\n",
    "\n",
    "# Register execution type to the Metadata Store\n",
    "dv_execution_type_id = store.put_execution_type(dv_execution_type)\n",
    "\n",
    "print('Data validation execution type:\\n', dv_execution_type)\n",
    "print('Data validation execution type ID:', dv_execution_type_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data artifact:\n",
      " type_id: 10\n",
      "uri: \"./data/train/data.csv\"\n",
      "properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"Chicago Taxi dataset\"\n",
      "  }\n",
      "}\n",
      "properties {\n",
      "  key: \"split\"\n",
      "  value {\n",
      "    string_value: \"train\"\n",
      "  }\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value {\n",
      "    int_value: 1\n",
      "  }\n",
      "}\n",
      "\n",
      "Data artifact ID: 1\n"
     ]
    }
   ],
   "source": [
    "# Generate input artifact unit: https://github.com/hsuyuming/ml-metadata/blob/master/ml_metadata/proto/metadata_store.proto\n",
    "# Declare input artifact of type Dataset\n",
    "data_artifact = metadata_store_pb2.Artifact()\n",
    "data_artifact.uri = './data/train/data.csv'\n",
    "data_artifact.type_id = data_artifact_type_id\n",
    "data_artifact.properties['name'].string_value = 'Chicago Taxi dataset'\n",
    "data_artifact.properties['split'].string_value = 'train'\n",
    "data_artifact.properties['version'].int_value = 1\n",
    "\n",
    "# Submit input artifact to the Metadata Store\n",
    "data_artifact_id = store.put_artifacts([data_artifact])[0]\n",
    "print('Data artifact:\\n', data_artifact)\n",
    "print('Data artifact ID:', data_artifact_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data validation execution:\n",
      " type_id: 12\n",
      "properties {\n",
      "  key: \"state\"\n",
      "  value {\n",
      "    string_value: \"RUNNING\"\n",
      "  }\n",
      "}\n",
      "\n",
      "Data validation execution ID: 1\n"
     ]
    }
   ],
   "source": [
    "# Generate execution unit: https://github.com/hsuyuming/ml-metadata/blob/master/ml_metadata/proto/metadata_store.proto\n",
    "# Register the Execution of a Data Validation run\n",
    "dv_execution = metadata_store_pb2.Execution()\n",
    "dv_execution.type_id = dv_execution_type_id\n",
    "dv_execution.properties['state'].string_value = 'RUNNING'\n",
    "\n",
    "dv_execution_id = store.put_executions([dv_execution])[0]\n",
    "print('Data validation execution:\\n', dv_execution)\n",
    "print('Data validation execution ID:', dv_execution_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input event:\n",
      " artifact_id: 1\n",
      "execution_id: 1\n",
      "type: DECLARED_INPUT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rigister input event\n",
    "# Declare the input event\n",
    "input_event = metadata_store_pb2.Event()\n",
    "input_event.artifact_id = data_artifact_id\n",
    "input_event.execution_id = dv_execution_id\n",
    "input_event.type = metadata_store_pb2.Event.DECLARED_INPUT\n",
    "\n",
    "store.put_events([input_event])\n",
    "\n",
    "print('Input event:\\n', input_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n        if (typeof window.interactive_beam_jquery == 'undefined') {\n          var jqueryScript = document.createElement('script');\n          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n          jqueryScript.type = 'text/javascript';\n          jqueryScript.onload = function() {\n            var datatableScript = document.createElement('script');\n            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n            datatableScript.type = 'text/javascript';\n            datatableScript.onload = function() {\n              window.interactive_beam_jquery = jQuery.noConflict(true);\n              window.interactive_beam_jquery(document).ready(function($){\n                \n              });\n            }\n            document.head.appendChild(datatableScript);\n          };\n          document.head.appendChild(jqueryScript);\n        } else {\n          window.interactive_beam_jquery(document).ready(function($){\n            \n          });\n        }"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.9 interpreter.\n",
      "WARNING:apache_beam.io.tfrecordio:Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/abehsu/.local/share/virtualenvs/feature_selection-yCDCSZCi/lib/python3.9/site-packages/tensorflow_data_validation/utils/statistics_io_impl.py:100: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/abehsu/.local/share/virtualenvs/feature_selection-yCDCSZCi/lib/python3.9/site-packages/tensorflow_data_validation/utils/statistics_io_impl.py:100: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset's Schema has been generated at: ./schema.pbtxt\n"
     ]
    }
   ],
   "source": [
    "# Run the TFDV(tensorflow DataValidation) component\n",
    "# Infer a schema by passing statistics to `infer_schema()`\n",
    "\n",
    "train_data = './data/train/data.csv'\n",
    "train_stats = tfdv.generate_statistics_from_csv(data_location=train_data)\n",
    "schema = tfdv.infer_schema(statistics=train_stats)\n",
    "\n",
    "schema_file = './schema.pbtxt'\n",
    "tfdv.write_schema_text(schema, schema_file)\n",
    "\n",
    "print(\"Dataset's Schema has been generated at:\", schema_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema artifact:\n",
      " type_id: 11\n",
      "uri: \"./schema.pbtxt\"\n",
      "properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"Chicago Taxi Schema\"\n",
      "  }\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value {\n",
      "    int_value: 1\n",
      "  }\n",
      "}\n",
      "\n",
      "Schema artifact ID: 2\n"
     ]
    }
   ],
   "source": [
    "# Generate output artifact unit\n",
    "# Declare output artifact of type Schema_artifact\n",
    "schema_artifact = metadata_store_pb2.Artifact()\n",
    "schema_artifact.uri = schema_file\n",
    "schema_artifact.type_id = schema_artifact_type_id\n",
    "schema_artifact.properties['version'].int_value = 1\n",
    "schema_artifact.properties['name'].string_value = 'Chicago Taxi Schema'\n",
    "\n",
    "# Submit output artifact to the Metadata Store\n",
    "schema_artifact_id = store.put_artifacts([schema_artifact])[0]\n",
    "\n",
    "print('Schema artifact:\\n', schema_artifact)\n",
    "print('Schema artifact ID:', schema_artifact_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output event:\n",
      " artifact_id: 2\n",
      "execution_id: 1\n",
      "type: DECLARED_OUTPUT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Register output event\n",
    "output_event = metadata_store_pb2.Event()\n",
    "output_event.artifact_id = schema_artifact_id\n",
    "output_event.execution_id = dv_execution_id\n",
    "output_event.type = metadata_store_pb2.Event.DECLARED_OUTPUT\n",
    "\n",
    "# Submit output event to the Metadata Store\n",
    "store.put_events([output_event])\n",
    "\n",
    "print('Output event:\\n', output_event)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data validation execution:\n",
      " id: 1\n",
      "type_id: 12\n",
      "properties {\n",
      "  key: \"state\"\n",
      "  value {\n",
      "    string_value: \"COMPLETED\"\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Update the execution unit\n",
    "dv_execution.id = dv_execution_id\n",
    "dv_execution.properties['state'].string_value = 'COMPLETED'\n",
    "\n",
    "store.put_executions([dv_execution])\n",
    "\n",
    "print('Data validation execution:\\n', dv_execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up Context Types and Generating a Context Unit\n",
    "# Create a ContextType\n",
    "expt_context_type = metadata_store_pb2.ContextType()\n",
    "expt_context_type.name = 'Experiment'\n",
    "expt_context_type.properties['note'] = metadata_store_pb2.STRING\n",
    "\n",
    "# Register context type to the Metadata Store\n",
    "expt_context_type_id = store.put_context_type(expt_context_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Context type:\n",
      " name: \"Experiment\"\n",
      "properties {\n",
      "  key: \"note\"\n",
      "  value: STRING\n",
      "}\n",
      "\n",
      "Experiment Context type ID:  13\n",
      "Experiment Context:\n",
      " type_id: 13\n",
      "name: \"Demo\"\n",
      "properties {\n",
      "  key: \"note\"\n",
      "  value {\n",
      "    string_value: \"Walkthrough of metadata\"\n",
      "  }\n",
      "}\n",
      "\n",
      "Experiment Context ID:  1\n"
     ]
    }
   ],
   "source": [
    "# Generate the context \n",
    "expt_context = metadata_store_pb2.Context()\n",
    "expt_context.type_id = expt_context_type_id\n",
    "expt_context.name = 'Demo'\n",
    "expt_context.properties['note'].string_value = 'Walkthrough of metadata'\n",
    "\n",
    "expt_context_id = store.put_contexts([expt_context])[0]\n",
    "print('Experiment Context type:\\n', expt_context_type)\n",
    "print('Experiment Context type ID: ', expt_context_type_id)\n",
    "\n",
    "print('Experiment Context:\\n', expt_context)\n",
    "print('Experiment Context ID: ', expt_context_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Attribution:\n",
      " artifact_id: 2\n",
      "context_id: 1\n",
      "\n",
      "Experiment Association:\n",
      " execution_id: 1\n",
      "context_id: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate attribution and association relationships\n",
    "# Generate the attribution\n",
    "expt_attribution = metadata_store_pb2.Attribution()\n",
    "expt_attribution.artifact_id = schema_artifact_id\n",
    "expt_attribution.context_id = expt_context_id\n",
    "\n",
    "# Generate the association\n",
    "expt_association = metadata_store_pb2.Association()\n",
    "expt_association.execution_id = dv_execution_id\n",
    "expt_association.context_id = expt_context_id\n",
    "\n",
    "# Submit attribution and association to the Metadata Store\n",
    "expt_association.context_id = expt_context_id\n",
    "store.put_attributions_and_associations([expt_attribution],[expt_association])\n",
    "print('Experiment Attribution:\\n', expt_attribution)\n",
    "print('Experiment Association:\\n', expt_association)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[id: 10\n",
       " name: \"DataSet\"\n",
       " properties {\n",
       "   key: \"name\"\n",
       "   value: STRING\n",
       " }\n",
       " properties {\n",
       "   key: \"split\"\n",
       "   value: STRING\n",
       " }\n",
       " properties {\n",
       "   key: \"version\"\n",
       "   value: INT\n",
       " },\n",
       " id: 11\n",
       " name: \"Schema\"\n",
       " properties {\n",
       "   key: \"name\"\n",
       "   value: STRING\n",
       " }\n",
       " properties {\n",
       "   key: \"version\"\n",
       "   value: INT\n",
       " }]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieving information from the Metadata Store\n",
    "# Get artifact types\n",
    "store.get_artifact_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 2\n",
      "type_id: 11\n",
      "uri: \"./schema.pbtxt\"\n",
      "properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"Chicago Taxi Schema\"\n",
      "  }\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value {\n",
      "    int_value: 1\n",
      "  }\n",
      "}\n",
      "create_time_since_epoch: 1653864627769\n",
      "last_update_time_since_epoch: 1653864627769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema_to_inv = store.get_artifacts_by_type('Schema')[0]\n",
    "# print output\n",
    "print(schema_to_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[artifact_id: 2\n",
      "execution_id: 1\n",
      "type: DECLARED_OUTPUT\n",
      "milliseconds_since_epoch: 1653864664112\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Get events related to the schema id \n",
    "schema_events = store.get_events_by_artifact_ids([schema_to_inv.id])\n",
    "print(schema_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[artifact_id: 1\n",
      "execution_id: 1\n",
      "type: DECLARED_INPUT\n",
      "milliseconds_since_epoch: 1653864369495\n",
      ", artifact_id: 2\n",
      "execution_id: 1\n",
      "type: DECLARED_OUTPUT\n",
      "milliseconds_since_epoch: 1653864664112\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Get events related to the output above\n",
    "execution_events = store.get_events_by_execution_ids([schema_events[0].execution_id])\n",
    "\n",
    "print(execution_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[id: 1\n",
       " type_id: 10\n",
       " uri: \"./data/train/data.csv\"\n",
       " properties {\n",
       "   key: \"name\"\n",
       "   value {\n",
       "     string_value: \"Chicago Taxi dataset\"\n",
       "   }\n",
       " }\n",
       " properties {\n",
       "   key: \"split\"\n",
       "   value {\n",
       "     string_value: \"train\"\n",
       "   }\n",
       " }\n",
       " properties {\n",
       "   key: \"version\"\n",
       "   value {\n",
       "     int_value: 1\n",
       "   }\n",
       " }\n",
       " create_time_since_epoch: 1653864032130\n",
       " last_update_time_since_epoch: 1653864032130]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look up the artifact that is a declared input\n",
    "artifact_input = execution_events[0]\n",
    "\n",
    "store.get_artifacts_by_id([artifact_input.artifact_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "de36a28a33616890cf2401fde3034eb97c797c728c8af7d284a82fdd031d05f2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('feature_selection-yCDCSZCi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
